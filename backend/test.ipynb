{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\PipeMaven\\testing\\compas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                           int64\n",
      "name                        object\n",
      "first                       object\n",
      "last                        object\n",
      "compas_screening_date       object\n",
      "sex                         object\n",
      "dob                         object\n",
      "age                          int64\n",
      "age_cat                     object\n",
      "race                        object\n",
      "juv_fel_count                int64\n",
      "decile_score                 int64\n",
      "juv_misd_count               int64\n",
      "juv_other_count              int64\n",
      "priors_count                 int64\n",
      "days_b_screening_arrest    float64\n",
      "c_jail_in                   object\n",
      "c_jail_out                  object\n",
      "c_case_number               object\n",
      "c_offense_date              object\n",
      "c_arrest_date               object\n",
      "c_days_from_compas         float64\n",
      "c_charge_degree             object\n",
      "c_charge_desc               object\n",
      "is_recid                     int64\n",
      "r_case_number               object\n",
      "r_charge_degree             object\n",
      "r_days_from_arrest         float64\n",
      "r_offense_date              object\n",
      "r_charge_desc               object\n",
      "r_jail_in                   object\n",
      "r_jail_out                  object\n",
      "violent_recid              float64\n",
      "is_violent_recid             int64\n",
      "vr_case_number              object\n",
      "vr_charge_degree            object\n",
      "vr_offense_date             object\n",
      "vr_charge_desc              object\n",
      "type_of_assessment          object\n",
      "decile_score.1               int64\n",
      "score_text                  object\n",
      "screening_date              object\n",
      "v_type_of_assessment        object\n",
      "v_decile_score               int64\n",
      "v_score_text                object\n",
      "v_screening_date            object\n",
      "in_custody                  object\n",
      "out_custody                 object\n",
      "priors_count.1               int64\n",
      "start                        int64\n",
      "end                          int64\n",
      "event                        int64\n",
      "two_year_recid               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "types = df.dtypes\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(types.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                mean  median  mode      std_dev    range\n",
      "id                       5501.255753  5509.5   NaN  3175.706870  11000.0\n",
      "age                        34.817993    31.0  24.0    11.888922     78.0\n",
      "juv_fel_count               0.067230     0.0   0.0     0.473972     20.0\n",
      "decile_score                4.509565     4.0   1.0     2.856396      9.0\n",
      "juv_misd_count              0.090934     0.0   0.0     0.485239     13.0\n",
      "juv_other_count             0.109371     0.0   0.0     0.501586     17.0\n",
      "priors_count                3.472415     2.0   0.0     4.882538     38.0\n",
      "days_b_screening_arrest     3.304763    -1.0  -1.0    75.809505   1471.0\n",
      "c_days_from_compas         57.731368     1.0   1.0   329.740215   9485.0\n",
      "is_recid                    0.481148     0.0   0.0     0.499679      1.0\n",
      "r_days_from_arrest         20.269430     0.0   0.0    74.871668    994.0\n",
      "violent_recid                    NaN     NaN   NaN          NaN      NaN\n",
      "is_violent_recid            0.113529     0.0   0.0     0.317261      1.0\n",
      "decile_score.1              4.509565     4.0   1.0     2.856396      9.0\n",
      "v_decile_score              3.691849     3.0   1.0     2.510148      9.0\n",
      "priors_count.1              3.472415     2.0   0.0     4.882538     38.0\n",
      "start                      11.465068     0.0   0.0    46.954563    937.0\n",
      "end                       553.436651   530.5  21.0   399.020583   1186.0\n",
      "event                       0.382867     0.0   0.0     0.486120      1.0\n",
      "two_year_recid              0.450652     0.0   0.0     0.497593      1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rocci\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        # Mean\n",
    "        mean_value = df[column].mean()\n",
    "\n",
    "        # Median\n",
    "        median_value = df[column].median()\n",
    "\n",
    "        # Mode\n",
    "        mode_value = statistics.mode(df[column]) if len(set(df[column])) < len(df[column]) else None\n",
    "\n",
    "        # Standard Deviation\n",
    "        std_dev_value = df[column].std()\n",
    "\n",
    "        # Range\n",
    "        range_value = df[column].max() - df[column].min()\n",
    "\n",
    "        result_dict[column] = {\n",
    "            \"mean\": mean_value,\n",
    "            \"median\": median_value,\n",
    "            \"mode\": mode_value,\n",
    "            \"std_dev\": std_dev_value,\n",
    "            \"range\": range_value\n",
    "            }\n",
    "\n",
    "result_df = pd.DataFrame(result_dict).T\n",
    "print(str(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(column):\n",
    "    Q1 = column.quantile(0.25)\n",
    "    Q3 = column.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = (column < lower_bound) | (column > upper_bound)\n",
    "    return outliers\n",
    "\n",
    "def scoring(df):\n",
    "    delete_or_fill = []\n",
    "    outliers = []\n",
    "    # delete or fill\n",
    "    for column in df.columns:\n",
    "        SDC = df[column].isnull().sum()/df.shape[0]\n",
    "        if SDC != 0.0:\n",
    "            formatted_SDC = \"{:.2f}\".format(SDC*100)\n",
    "            delete_or_fill.append(column + ': ' + formatted_SDC + '%')\n",
    "    \n",
    "    # filter outliers\n",
    "    columns = df.select_dtypes(include = [int, float]).columns\n",
    "    for column in columns:\n",
    "        out = identify_outliers(df[column]).sum()/df.shape[0]\n",
    "        formatted_out = \"{:.2f}\".format(out*100)\n",
    "        outliers.append(column + ': ' + formatted_out + '%')\n",
    "\n",
    "    return ('Delete: ' + str(delete_or_fill) + '\\nFilter Outliers: ' + str(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preparators(df):\n",
    "    rows = df.shape[0]\n",
    "    n_columns = df.shape[1]\n",
    "    #\n",
    "    delete = []\n",
    "    fill = []\n",
    "    outliers = []\n",
    "    # delete or fill\n",
    "    for column in df.columns:\n",
    "        SDC = df[column].isnull().sum()/df.shape[0]\n",
    "        if SDC != 0.0:\n",
    "            print(SDC)\n",
    "            formatted_SDC = \"{:.2f}\".format(SDC*100)\n",
    "            if SDC >= 0.25:\n",
    "                delete.append(column + ': ' + formatted_SDC + '%')\n",
    "            else:\n",
    "                fill.append(column + ': ' + formatted_SDC + '%')\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            out = identify_outliers(df[column]).sum()/df.shape[0]\n",
    "            formatted_out = \"{:.2f}\".format(out*100)\n",
    "            outliers.append(column + ': ' + formatted_out + '%')\n",
    "    return \"Delete column: \" + str(delete) + \"\\nFill column: \" + str(fill) + \"\\nOutliers: \" + str(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042556140837260885\n",
      "0.042556140837260885\n",
      "0.042556140837260885\n",
      "0.003049625727751594\n",
      "0.16065982811200444\n",
      "0.8423897976157472\n",
      "0.003049625727751594\n",
      "0.004019961186581647\n",
      "0.5188522317715553\n",
      "0.5188522317715553\n",
      "0.678957582478514\n",
      "0.5188522317715553\n",
      "0.5268921541447186\n",
      "0.678957582478514\n",
      "0.678957582478514\n",
      "1.0\n",
      "0.8864707513168838\n",
      "0.8864707513168838\n",
      "0.8864707513168838\n",
      "0.8864707513168838\n",
      "0.03271416689769892\n",
      "0.03271416689769892\n",
      "Delete column: ['c_arrest_date: 84.24%', 'r_case_number: 51.89%', 'r_charge_degree: 51.89%', 'r_days_from_arrest: 67.90%', 'r_offense_date: 51.89%', 'r_charge_desc: 52.69%', 'r_jail_in: 67.90%', 'r_jail_out: 67.90%', 'violent_recid: 100.00%', 'vr_case_number: 88.65%', 'vr_charge_degree: 88.65%', 'vr_offense_date: 88.65%', 'vr_charge_desc: 88.65%']\n",
      "Fill column: ['days_b_screening_arrest: 4.26%', 'c_jail_in: 4.26%', 'c_jail_out: 4.26%', 'c_case_number: 0.30%', 'c_offense_date: 16.07%', 'c_days_from_compas: 0.30%', 'c_charge_desc: 0.40%', 'in_custody: 3.27%', 'out_custody: 3.27%']\n",
      "Outliers: ['id: 0.00%', 'age: 0.85%', 'juv_fel_count: 3.91%', 'decile_score: 0.00%', 'juv_misd_count: 5.75%', 'juv_other_count: 7.25%', 'priors_count: 6.31%', 'days_b_screening_arrest: 19.37%', 'c_days_from_compas: 21.43%', 'is_recid: 0.00%', 'r_days_from_arrest: 4.75%', 'violent_recid: 0.00%', 'is_violent_recid: 11.35%', 'decile_score.1: 0.00%', 'v_decile_score: 0.00%', 'priors_count.1: 6.31%', 'start: 21.62%', 'end: 0.00%', 'event: 0.00%', 'two_year_recid: 0.00%']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\PipeMaven\\testing\\compas.csv')\n",
    "print(get_preparators(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete: ['days_b_screening_arrest: 4.26%', 'c_jail_in: 4.26%', 'c_jail_out: 4.26%', 'c_case_number: 0.30%', 'c_offense_date: 16.07%', 'c_arrest_date: 84.24%', 'c_days_from_compas: 0.30%', 'c_charge_desc: 0.40%', 'r_case_number: 51.89%', 'r_charge_degree: 51.89%', 'r_days_from_arrest: 67.90%', 'r_offense_date: 51.89%', 'r_charge_desc: 52.69%', 'r_jail_in: 67.90%', 'r_jail_out: 67.90%', 'violent_recid: 100.00%', 'vr_case_number: 88.65%', 'vr_charge_degree: 88.65%', 'vr_offense_date: 88.65%', 'vr_charge_desc: 88.65%', 'in_custody: 3.27%', 'out_custody: 3.27%']\n",
      "Filter Outliers: ['id: 0.00%', 'age: 0.85%', 'juv_fel_count: 3.91%', 'decile_score: 0.00%', 'juv_misd_count: 5.75%', 'juv_other_count: 7.25%', 'priors_count: 6.31%', 'days_b_screening_arrest: 19.37%', 'c_days_from_compas: 21.43%', 'is_recid: 0.00%', 'r_days_from_arrest: 4.75%', 'violent_recid: 0.00%', 'is_violent_recid: 11.35%', 'decile_score.1: 0.00%', 'v_decile_score: 0.00%', 'priors_count.1: 6.31%', 'start: 21.62%', 'end: 0.00%', 'event: 0.00%', 'two_year_recid: 0.00%']\n"
     ]
    }
   ],
   "source": [
    "res = scoring(df)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(df, label):\n",
    "    try:\n",
    "        features = [col for col in df.columns if col != label]\n",
    "        X = df[features]\n",
    "        y = df[label]\n",
    "        train_x, test_x, train_y, test_y = train_test_split(X, y, random_state=1)\n",
    "        tree = HistGradientBoostingClassifier(random_state = 0)\n",
    "        tree.fit(train_x, train_y)\n",
    "        y_pred_tree = tree.predict(test_x)\n",
    "        score_tree = accuracy_score(test_y,y_pred_tree)\n",
    "        return round(score_tree*100,2)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "    \n",
    "def get_entropy(df):\n",
    "    i = 0\n",
    "    total = 0\n",
    "    for column in df.columns:\n",
    "        counts = df[column].value_counts()\n",
    "        prob = counts/len(df)\n",
    "        entropy_value = entropy(prob, base = 2)\n",
    "        total += entropy_value\n",
    "        i += 1\n",
    "    shannon_entropy = total/i\n",
    "    return shannon_entropy\n",
    "\n",
    "def check_changes(df_start, df_end):\n",
    "    # Different shapes => cell removed/added\n",
    "    if df_start.shape != df_end.shape:\n",
    "        row_diff = df_end.shape[0] - df_start.shape[0]\n",
    "        cols_diff = df_end.shape[1] - df_start.shape[1]\n",
    "        differences = row_diff * df_start.shape[1] + cols_diff * df_start.shape[0]\n",
    "    # Same shape => cell modified\n",
    "    else:\n",
    "        differences = (df_start != df_end).sum().sum()\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.5340027s,\n",
      "Completeness Before Pipeline: 100.0%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 2.8781066070808152,\n",
      "Average Shannon's Entropy After Pipeline: 0.3373531744120834,\n",
      "Accuracy on a ML Algorithm Before Pipeline: could not convert string to float: ' Private',\n",
      "Accuracy on a ML Algorithm After Pipeline: 87.57,\n",
      "# Cells Modified: 2995612\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\testing\\census.csv')\n",
    "accuracy_start = check_accuracy(df, '14')\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "df_start = df\n",
    "start_time = time.time_ns()\n",
    "\n",
    "df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'label']\n",
    "columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'label']\n",
    "df_modified = df.replace('?', np.nan)\n",
    "df_modified[columns] = df_modified[columns].applymap(str.strip)\n",
    "columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'native-country']\n",
    "for i, col in enumerate(columns):   \n",
    "    dummies = pd.get_dummies(df_modified[col])\n",
    "    df_dummies = dummies.add_prefix(col + '_')\n",
    "    df_modified = df_modified.join(df_dummies)        \n",
    "    df_modified = df_modified.drop([col], axis=1)\n",
    "df_modified = df_modified.replace({'sex': {'Male': 1, 'Female': 0}, 'label': {'<=50K': 0, '>50K': 1}})\n",
    "df_modified = df_modified.drop(['fnlwgt'], axis=1)\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "\n",
    "accuracy_end = check_accuracy(df_modified, 'label')\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1_000_000_000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\data\\output\\output1.csv', index = False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.0411182s,\n",
      "Completeness Before Pipeline: 81.37269774181232%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 5.599599641948954,\n",
      "Average Shannon's Entropy After Pipeline: 2.4483103142809326,\n",
      "Accuracy on a ML Algorithm Before Pipeline: could not convert string to float: 'stephanie nevels',\n",
      "Accuracy on a ML Algorithm After Pipeline: 66.82,\n",
      "# Cells Modified: -340901\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\testing\\compas.csv')\n",
    "accuracy_start = check_accuracy(df, 'two_year_recid')\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "df_start = df\n",
    "start_time = time.time_ns()\n",
    "\n",
    "columns = ['age', 'c_charge_degree', 'race', 'sex', 'priors_count', 'days_b_screening_arrest', 'two_year_recid', 'c_jail_in', 'c_jail_out']\n",
    "df_modified = df.drop(df.columns.difference(columns), axis=1)\n",
    "df_modified = df_modified.dropna()\n",
    "df_modified['race'] = [0 if r != 'Caucasian' else 1 for r in df_modified['race']]\n",
    "df_modified = df_modified.rename({'two_year_recid': 'label'}, axis=1)\n",
    "df_modified['label'] = [0 if l == 1 else 1 for l in df_modified['label']]\n",
    "df_modified['sex'] = df_modified['sex'].replace({'Male': 1, 'Female': 0})\n",
    "df_modified['jailtime'] = (pd.to_datetime(df_modified.c_jail_out) - pd.to_datetime(df_modified.c_jail_in)).dt.days\n",
    "df_modified = df_modified.drop(['c_jail_in', 'c_jail_out'], axis=1)\n",
    "df_modified['c_charge_degree'] = [0 if s == 'M' else 1 for s in df_modified['c_charge_degree']]\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "\n",
    "accuracy_end = check_accuracy(df_modified, 'label')\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1_000_000_000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\data\\output\\output2.csv', index = False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.1070304s,\n",
      "Completeness Before Pipeline: 100.0%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 2.084195887922238,\n",
      "Average Shannon's Entropy After Pipeline: 0.9285827754815593,\n",
      "Accuracy on a ML Algorithm Before Pipeline: could not convert string to float: 'A14',\n",
      "Accuracy on a ML Algorithm After Pipeline: 74.4,\n",
      "# Cells Modified: 39000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\testing\\german.csv')\n",
    "accuracy_start = check_accuracy(df, 'label')\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "df_start = df\n",
    "start_time = time.time_ns()\n",
    "\n",
    "df = df.replace({'checking': {'A11': 'check_low', 'A12': 'check_mid', 'A13': 'check_high',\n",
    "                                  'A14': 'check_none'},\n",
    "                     'credit_history': {'A30': 'debt_none', 'A31': 'debt_noneBank',\n",
    "                                        'A32': 'debt_onSchedule', 'A33': 'debt_delay',\n",
    "                                        'A34': 'debt_critical'},\n",
    "                     'purpose': {'A40': 'pur_newCar', 'A41': 'pur_usedCar',\n",
    "                                 'A42': 'pur_furniture', 'A43': 'pur_tv',\n",
    "                                 'A44': 'pur_appliance', 'A45': 'pur_repairs',\n",
    "                                 'A46': 'pur_education', 'A47': 'pur_vacation',\n",
    "                                 'A48': 'pur_retraining', 'A49': 'pur_business',\n",
    "                                 'A410': 'pur_other'},\n",
    "                     'savings': {'A61': 'sav_small', 'A62': 'sav_medium', 'A63': 'sav_large',\n",
    "                                 'A64': 'sav_xlarge', 'A65': 'sav_none'},\n",
    "                     'employment': {'A71': 'emp_unemployed', 'A72': 'emp_lessOne',\n",
    "                                    'A73': 'emp_lessFour', 'A74': 'emp_lessSeven',\n",
    "                                    'A75': 'emp_moreSeven'},\n",
    "                     'other_debtors': {'A101': 'debtor_none', 'A102': 'debtor_coApp',\n",
    "                                       'A103': 'debtor_guarantor'},\n",
    "                     'property': {'A121': 'prop_realEstate', 'A122': 'prop_agreement',\n",
    "                                  'A123': 'prop_car', 'A124': 'prop_none'},\n",
    "                     'other_inst': {'A141': 'oi_bank', 'A142': 'oi_stores', 'A143': 'oi_none'},\n",
    "                     'housing': {'A151': 'hous_rent', 'A152': 'hous_own', 'A153': 'hous_free'},\n",
    "                     'job': {'A171': 'job_unskilledNR', 'A172': 'job_unskilledR',\n",
    "                             'A173': 'job_skilled', 'A174': 'job_highSkill'},\n",
    "                     'phone': {'A191': 0, 'A192': 1},\n",
    "                     'foreigner': {'A201': 1, 'A202': 0},\n",
    "                     'label': {2: 0}})\n",
    "df['status'] = np.where(df.personal_status == 'A91', 'divorced',\n",
    "                            np.where(df.personal_status == 'A92', 'divorced',\n",
    "                                     np.where(df.personal_status == 'A93', 'single',\n",
    "                                              np.where(df.personal_status == 'A95', 'single',\n",
    "                                                       'married'))))\n",
    "df['gender'] = np.where(df.personal_status == 'A92', 0, np.where(df.personal_status == 'A95', 0, 1))\n",
    "df_modified = df.drop(['personal_status'], axis=1)\n",
    "columns = ['checking', 'credit_history', 'purpose', 'savings', 'employment', 'other_debtors', 'property',\n",
    "           'other_inst', 'housing', 'job', 'status']\n",
    "for i, col in enumerate(columns):\n",
    "    dummies = pd.get_dummies(df_modified[col])\n",
    "    df_dummies = dummies.add_prefix(col + '_')\n",
    "    df_modified = df_modified.join(df_dummies)\n",
    "    df_modified = df_modified.drop([col], axis=1)\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "\n",
    "accuracy_end = check_accuracy(df_modified, 'label')\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1000000000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\data\\output\\output3.csv', index = False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocci\\AppData\\Local\\Temp\\ipykernel_38140\\1132282002.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_modified['Class'] = label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.1287323s,\n",
      "Completeness Before Pipeline: 100.0%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 4.428688739721966,\n",
      "Average Shannon's Entropy After Pipeline: 0.18106952412414623,\n",
      "Accuracy on a ML Algorithm Before Pipeline: 74.33,\n",
      "Accuracy on a ML Algorithm After Pipeline: 77.54,\n",
      "# Cells Modified: 127908\n",
      "(748, 177)\n",
      "(748, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\testing\\transfusion.csv')\n",
    "accuracy_start = check_accuracy(df, 'Class')\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "start_time = time.time_ns()\n",
    "\n",
    "df['Class'] = df['Class'].replace({1: 0, 2: 1})\n",
    "label = df['Class']\n",
    "df = df.drop(['Class'], axis = 1)\n",
    "columns = ['V1', 'V2', 'V3', 'V4']\n",
    "for i, col in enumerate(columns):\n",
    "    dummies = pd.get_dummies(df[col])\n",
    "    df_dummies = dummies.add_prefix(col + '_')\n",
    "    df = df.join(df_dummies)\n",
    "    df = df.drop([col], axis=1)\n",
    "imputer = SimpleImputer(strategy='median', copy=True)\n",
    "df = imputer.fit_transform(df)\n",
    "df_modified = pd.DataFrame(df)\n",
    "scaler = StandardScaler(with_mean=False, with_std=True)\n",
    "columns = df_modified.columns[1:]\n",
    "df_modified[columns] = scaler.fit_transform(df_modified[columns])\n",
    "df_modified['Class'] = label\n",
    "\n",
    "#df_modified = df_modified.astype(df_start.dtypes)\n",
    "\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "df_start = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\testing\\transfusion.csv')\n",
    "accuracy_end = check_accuracy(df_modified, 'Class')\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1000000000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\data\\output\\output4.csv', index = False)\n",
    "print(response)\n",
    "print(df_modified.shape)\n",
    "print(df_start.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.0099998s,\n",
      "Completeness Before Pipeline: 100.0%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 6.411632038013595,\n",
      "Average Shannon's Entropy After Pipeline: 6.411632038013595,\n",
      "Accuracy on a ML Algorithm Before Pipeline: 92.73,\n",
      "Accuracy on a ML Algorithm After Pipeline: 92.73,\n",
      "# Cells Modified: 3080\n",
      "(440, 10)\n",
      "(440, 10)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\testing\\customers.csv')\n",
    "accuracy_start = check_accuracy(df, 'Channel')\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "df_modified = pd.DataFrame()\n",
    "start_time = time.time_ns()\n",
    "\n",
    "scaler = StandardScaler(with_mean=False, with_std=True)\n",
    "columns = ['V2', 'V3', 'V4', 'V5', 'V6', 'V7']\n",
    "df[columns] = scaler.fit_transform(df[columns])\n",
    "df['Channel'] = df['Channel'].replace({1: 0, 2: 1})\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "df_modified = df\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "df_start = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\testing\\customers.csv')\n",
    "accuracy_end = check_accuracy(df_modified, 'Channel')\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1_000_000_000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\data\\output\\output5.csv', index = False)\n",
    "print(response)\n",
    "print(df_start.shape)\n",
    "print(df_modified.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            303\n",
       "'age'          41\n",
       "'sex'           2\n",
       "'cp'            4\n",
       "'trestbps'     50\n",
       "'chol'        152\n",
       "'fbs'           2\n",
       "'restecg'       3\n",
       "'thalach'      91\n",
       "'exang'         2\n",
       "'oldpeak'      40\n",
       "'slope'         3\n",
       "'ca'            5\n",
       "'thal'          4\n",
       "'num'           5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\testing\\cleveland.csv')\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocci\\AppData\\Local\\Temp\\ipykernel_27888\\223515889.py:19: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  dummies = pd.get_dummies(df_modified[col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.0430057s,\n",
      "Completeness Before Pipeline: 99.86798679867987%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 3.104902911182914,\n",
      "Average Shannon's Entropy After Pipeline: 1.6911882470387252,\n",
      "Accuracy on a ML Algorithm Before Pipeline: 78.95,\n",
      "Accuracy on a ML Algorithm After Pipeline: 82.89,\n",
      "# Cells Modified: 1515\n",
      "(303, 15)\n",
      "(303, 20)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\testing\\cleveland.csv')\n",
    "df_start = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\testing\\cleveland.csv')\n",
    "df = df.replace({'?': np.nan})\n",
    "accuracy_start = check_accuracy(df, \"'fbs'\")\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "start_time = time.time_ns()\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent', copy=True)\n",
    "df = imputer.fit_transform(df)\n",
    "df_modified = pd.DataFrame(df)\n",
    "scaler = StandardScaler(with_mean=False, with_std=True)\n",
    "columns = df_modified.columns[1:-1]\n",
    "df_modified[columns] = scaler.fit_transform(df_modified[columns])\n",
    "df_modified.columns = df_start.columns\n",
    "df_modified = df_modified.astype(df_start.dtypes)\n",
    "columns = [\"'ca'\", \"'slope'\"]\n",
    "for i, col in enumerate(columns):\n",
    "        dummies = pd.get_dummies(df_modified[col])\n",
    "        df_dummies = dummies.add_prefix(col + '_')\n",
    "        df_modified = df_modified.join(df_dummies)\n",
    "        df_modified = df_modified.drop([col], axis=1)\n",
    "\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "accuracy_end = check_accuracy(df_modified, \"'fbs'\")\n",
    "\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1_000_000_000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Universit√†\\TesiMagistrale\\dataPreparationTool\\data\\output\\output6.csv', index = False)\n",
    "print(response)\n",
    "print(df_start.shape)\n",
    "print(df_modified.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
