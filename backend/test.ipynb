{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(df, label):\n",
    "    try:\n",
    "        features = [col for col in df.columns if col != label]\n",
    "        X = df[features]\n",
    "        y = df[label]\n",
    "        train_x, test_x, train_y, test_y = train_test_split(X, y, random_state=1)\n",
    "        tree = HistGradientBoostingClassifier(random_state = 0)\n",
    "        tree.fit(train_x, train_y)\n",
    "        y_pred_tree = tree.predict(test_x)\n",
    "        score_tree = accuracy_score(test_y,y_pred_tree)\n",
    "        return round(score_tree*100,2)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "    \n",
    "def get_entropy(df):\n",
    "    i = 0\n",
    "    total = 0\n",
    "    for column in df.columns:\n",
    "        counts = df[column].value_counts()\n",
    "        prob = counts/len(df)\n",
    "        entropy_value = entropy(prob, base = 2)\n",
    "        total += entropy_value\n",
    "        i += 1\n",
    "    shannon_entropy = total/i\n",
    "    return shannon_entropy\n",
    "\n",
    "def check_changes(df_start, df_end):\n",
    "    # Different shapes => cell removed/added\n",
    "    if df_start.shape != df_end.shape:\n",
    "        row_diff = df_end.shape[0] - df_start.shape[0]\n",
    "        cols_diff = df_end.shape[1] - df_start.shape[1]\n",
    "        differences = row_diff * df_start.shape[1] + cols_diff * df_start.shape[0]\n",
    "    # Same shape => cell modified\n",
    "    else:\n",
    "        differences = (df_start != df_end).sum().sum()\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.5340027s,\n",
      "Completeness Before Pipeline: 100.0%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 2.8781066070808152,\n",
      "Average Shannon's Entropy After Pipeline: 0.3373531744120834,\n",
      "Accuracy on a ML Algorithm Before Pipeline: could not convert string to float: ' Private',\n",
      "Accuracy on a ML Algorithm After Pipeline: 87.57,\n",
      "# Cells Modified: 2995612\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\testing\\census.csv')\n",
    "accuracy_start = check_accuracy(df, '14')\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "df_start = df\n",
    "start_time = time.time_ns()\n",
    "\n",
    "df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'label']\n",
    "columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'label']\n",
    "df_modified = df.replace('?', np.nan)\n",
    "df_modified[columns] = df_modified[columns].applymap(str.strip)\n",
    "columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'native-country']\n",
    "for i, col in enumerate(columns):   \n",
    "    dummies = pd.get_dummies(df_modified[col])\n",
    "    df_dummies = dummies.add_prefix(col + '_')\n",
    "    df_modified = df_modified.join(df_dummies)        \n",
    "    df_modified = df_modified.drop([col], axis=1)\n",
    "df_modified = df_modified.replace({'sex': {'Male': 1, 'Female': 0}, 'label': {'<=50K': 0, '>50K': 1}})\n",
    "df_modified = df_modified.drop(['fnlwgt'], axis=1)\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "\n",
    "accuracy_end = check_accuracy(df_modified, 'label')\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1_000_000_000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\data\\output\\output1.csv', index = False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.0411182s,\n",
      "Completeness Before Pipeline: 81.37269774181232%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 5.599599641948954,\n",
      "Average Shannon's Entropy After Pipeline: 2.4483103142809326,\n",
      "Accuracy on a ML Algorithm Before Pipeline: could not convert string to float: 'stephanie nevels',\n",
      "Accuracy on a ML Algorithm After Pipeline: 66.82,\n",
      "# Cells Modified: -340901\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\testing\\compas.csv')\n",
    "accuracy_start = check_accuracy(df, 'two_year_recid')\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "df_start = df\n",
    "start_time = time.time_ns()\n",
    "\n",
    "columns = ['age', 'c_charge_degree', 'race', 'sex', 'priors_count', 'days_b_screening_arrest', 'two_year_recid', 'c_jail_in', 'c_jail_out']\n",
    "df_modified = df.drop(df.columns.difference(columns), axis=1)\n",
    "df_modified = df_modified.dropna()\n",
    "df_modified['race'] = [0 if r != 'Caucasian' else 1 for r in df_modified['race']]\n",
    "df_modified = df_modified.rename({'two_year_recid': 'label'}, axis=1)\n",
    "df_modified['label'] = [0 if l == 1 else 1 for l in df_modified['label']]\n",
    "df_modified['sex'] = df_modified['sex'].replace({'Male': 1, 'Female': 0})\n",
    "df_modified['jailtime'] = (pd.to_datetime(df_modified.c_jail_out) - pd.to_datetime(df_modified.c_jail_in)).dt.days\n",
    "df_modified = df_modified.drop(['c_jail_in', 'c_jail_out'], axis=1)\n",
    "df_modified['c_charge_degree'] = [0 if s == 'M' else 1 for s in df_modified['c_charge_degree']]\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "\n",
    "accuracy_end = check_accuracy(df_modified, 'label')\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1_000_000_000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\data\\output\\output2.csv', index = False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.1070304s,\n",
      "Completeness Before Pipeline: 100.0%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 2.084195887922238,\n",
      "Average Shannon's Entropy After Pipeline: 0.9285827754815593,\n",
      "Accuracy on a ML Algorithm Before Pipeline: could not convert string to float: 'A14',\n",
      "Accuracy on a ML Algorithm After Pipeline: 74.4,\n",
      "# Cells Modified: 39000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\testing\\german.csv')\n",
    "accuracy_start = check_accuracy(df, 'label')\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "df_start = df\n",
    "start_time = time.time_ns()\n",
    "\n",
    "df = df.replace({'checking': {'A11': 'check_low', 'A12': 'check_mid', 'A13': 'check_high',\n",
    "                                  'A14': 'check_none'},\n",
    "                     'credit_history': {'A30': 'debt_none', 'A31': 'debt_noneBank',\n",
    "                                        'A32': 'debt_onSchedule', 'A33': 'debt_delay',\n",
    "                                        'A34': 'debt_critical'},\n",
    "                     'purpose': {'A40': 'pur_newCar', 'A41': 'pur_usedCar',\n",
    "                                 'A42': 'pur_furniture', 'A43': 'pur_tv',\n",
    "                                 'A44': 'pur_appliance', 'A45': 'pur_repairs',\n",
    "                                 'A46': 'pur_education', 'A47': 'pur_vacation',\n",
    "                                 'A48': 'pur_retraining', 'A49': 'pur_business',\n",
    "                                 'A410': 'pur_other'},\n",
    "                     'savings': {'A61': 'sav_small', 'A62': 'sav_medium', 'A63': 'sav_large',\n",
    "                                 'A64': 'sav_xlarge', 'A65': 'sav_none'},\n",
    "                     'employment': {'A71': 'emp_unemployed', 'A72': 'emp_lessOne',\n",
    "                                    'A73': 'emp_lessFour', 'A74': 'emp_lessSeven',\n",
    "                                    'A75': 'emp_moreSeven'},\n",
    "                     'other_debtors': {'A101': 'debtor_none', 'A102': 'debtor_coApp',\n",
    "                                       'A103': 'debtor_guarantor'},\n",
    "                     'property': {'A121': 'prop_realEstate', 'A122': 'prop_agreement',\n",
    "                                  'A123': 'prop_car', 'A124': 'prop_none'},\n",
    "                     'other_inst': {'A141': 'oi_bank', 'A142': 'oi_stores', 'A143': 'oi_none'},\n",
    "                     'housing': {'A151': 'hous_rent', 'A152': 'hous_own', 'A153': 'hous_free'},\n",
    "                     'job': {'A171': 'job_unskilledNR', 'A172': 'job_unskilledR',\n",
    "                             'A173': 'job_skilled', 'A174': 'job_highSkill'},\n",
    "                     'phone': {'A191': 0, 'A192': 1},\n",
    "                     'foreigner': {'A201': 1, 'A202': 0},\n",
    "                     'label': {2: 0}})\n",
    "df['status'] = np.where(df.personal_status == 'A91', 'divorced',\n",
    "                            np.where(df.personal_status == 'A92', 'divorced',\n",
    "                                     np.where(df.personal_status == 'A93', 'single',\n",
    "                                              np.where(df.personal_status == 'A95', 'single',\n",
    "                                                       'married'))))\n",
    "df['gender'] = np.where(df.personal_status == 'A92', 0, np.where(df.personal_status == 'A95', 0, 1))\n",
    "df_modified = df.drop(['personal_status'], axis=1)\n",
    "columns = ['checking', 'credit_history', 'purpose', 'savings', 'employment', 'other_debtors', 'property',\n",
    "           'other_inst', 'housing', 'job', 'status']\n",
    "for i, col in enumerate(columns):\n",
    "    dummies = pd.get_dummies(df_modified[col])\n",
    "    df_dummies = dummies.add_prefix(col + '_')\n",
    "    df_modified = df_modified.join(df_dummies)\n",
    "    df_modified = df_modified.drop([col], axis=1)\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "\n",
    "accuracy_end = check_accuracy(df_modified, 'label')\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1000000000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\data\\output\\output3.csv', index = False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocci\\AppData\\Local\\Temp\\ipykernel_38140\\1132282002.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_modified['Class'] = label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.1287323s,\n",
      "Completeness Before Pipeline: 100.0%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 4.428688739721966,\n",
      "Average Shannon's Entropy After Pipeline: 0.18106952412414623,\n",
      "Accuracy on a ML Algorithm Before Pipeline: 74.33,\n",
      "Accuracy on a ML Algorithm After Pipeline: 77.54,\n",
      "# Cells Modified: 127908\n",
      "(748, 177)\n",
      "(748, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\testing\\transfusion.csv')\n",
    "accuracy_start = check_accuracy(df, 'Class')\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "start_time = time.time_ns()\n",
    "\n",
    "df['Class'] = df['Class'].replace({1: 0, 2: 1})\n",
    "label = df['Class']\n",
    "df = df.drop(['Class'], axis = 1)\n",
    "columns = ['V1', 'V2', 'V3', 'V4']\n",
    "for i, col in enumerate(columns):\n",
    "    dummies = pd.get_dummies(df[col])\n",
    "    df_dummies = dummies.add_prefix(col + '_')\n",
    "    df = df.join(df_dummies)\n",
    "    df = df.drop([col], axis=1)\n",
    "imputer = SimpleImputer(strategy='median', copy=True)\n",
    "df = imputer.fit_transform(df)\n",
    "df_modified = pd.DataFrame(df)\n",
    "scaler = StandardScaler(with_mean=False, with_std=True)\n",
    "columns = df_modified.columns[1:]\n",
    "df_modified[columns] = scaler.fit_transform(df_modified[columns])\n",
    "df_modified['Class'] = label\n",
    "\n",
    "#df_modified = df_modified.astype(df_start.dtypes)\n",
    "\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "df_start = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\testing\\transfusion.csv')\n",
    "accuracy_end = check_accuracy(df_modified, 'Class')\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1000000000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\data\\output\\output4.csv', index = False)\n",
    "print(response)\n",
    "print(df_modified.shape)\n",
    "print(df_start.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.0099998s,\n",
      "Completeness Before Pipeline: 100.0%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 6.411632038013595,\n",
      "Average Shannon's Entropy After Pipeline: 6.411632038013595,\n",
      "Accuracy on a ML Algorithm Before Pipeline: 92.73,\n",
      "Accuracy on a ML Algorithm After Pipeline: 92.73,\n",
      "# Cells Modified: 3080\n",
      "(440, 10)\n",
      "(440, 10)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\testing\\customers.csv')\n",
    "accuracy_start = check_accuracy(df, 'Channel')\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "df_modified = pd.DataFrame()\n",
    "start_time = time.time_ns()\n",
    "\n",
    "scaler = StandardScaler(with_mean=False, with_std=True)\n",
    "columns = ['V2', 'V3', 'V4', 'V5', 'V6', 'V7']\n",
    "df[columns] = scaler.fit_transform(df[columns])\n",
    "df['Channel'] = df['Channel'].replace({1: 0, 2: 1})\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "df_modified = df\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "df_start = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\testing\\customers.csv')\n",
    "accuracy_end = check_accuracy(df_modified, 'Channel')\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1_000_000_000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\data\\output\\output5.csv', index = False)\n",
    "print(response)\n",
    "print(df_start.shape)\n",
    "print(df_modified.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            303\n",
       "'age'          41\n",
       "'sex'           2\n",
       "'cp'            4\n",
       "'trestbps'     50\n",
       "'chol'        152\n",
       "'fbs'           2\n",
       "'restecg'       3\n",
       "'thalach'      91\n",
       "'exang'         2\n",
       "'oldpeak'      40\n",
       "'slope'         3\n",
       "'ca'            5\n",
       "'thal'          4\n",
       "'num'           5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\testing\\cleveland.csv')\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocci\\AppData\\Local\\Temp\\ipykernel_27888\\223515889.py:19: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  dummies = pd.get_dummies(df_modified[col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Execution Time: 0.0430057s,\n",
      "Completeness Before Pipeline: 99.86798679867987%,\n",
      "Completeness After Pipeline: 100.0%,\n",
      "Average Shannon's Entropy Before Pipeline: 3.104902911182914,\n",
      "Average Shannon's Entropy After Pipeline: 1.6911882470387252,\n",
      "Accuracy on a ML Algorithm Before Pipeline: 78.95,\n",
      "Accuracy on a ML Algorithm After Pipeline: 82.89,\n",
      "# Cells Modified: 1515\n",
      "(303, 15)\n",
      "(303, 20)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\testing\\cleveland.csv')\n",
    "df_start = pd.read_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\testing\\cleveland.csv')\n",
    "df = df.replace({'?': np.nan})\n",
    "accuracy_start = check_accuracy(df, \"'fbs'\")\n",
    "completeness_start = df.count()/df.shape[0]\n",
    "shannon_start = get_entropy(df)\n",
    "start_time = time.time_ns()\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent', copy=True)\n",
    "df = imputer.fit_transform(df)\n",
    "df_modified = pd.DataFrame(df)\n",
    "scaler = StandardScaler(with_mean=False, with_std=True)\n",
    "columns = df_modified.columns[1:-1]\n",
    "df_modified[columns] = scaler.fit_transform(df_modified[columns])\n",
    "df_modified.columns = df_start.columns\n",
    "df_modified = df_modified.astype(df_start.dtypes)\n",
    "columns = [\"'ca'\", \"'slope'\"]\n",
    "for i, col in enumerate(columns):\n",
    "        dummies = pd.get_dummies(df_modified[col])\n",
    "        df_dummies = dummies.add_prefix(col + '_')\n",
    "        df_modified = df_modified.join(df_dummies)\n",
    "        df_modified = df_modified.drop([col], axis=1)\n",
    "\n",
    "\n",
    "end_time = time.time_ns()\n",
    "total_time = end_time - start_time\n",
    "completeness_end = df_modified.count()/df_modified.shape[0]\n",
    "accuracy_end = check_accuracy(df_modified, \"'fbs'\")\n",
    "\n",
    "\n",
    "shannon_end = get_entropy(df_modified)\n",
    "differences = check_changes(df_start, df_modified)\n",
    "response = (\n",
    "    'Pipeline Execution Time: ' + str(total_time / 1_000_000_000) + 's,\\n' +\n",
    "    'Completeness Before Pipeline: ' + str(completeness_start.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    'Completeness After Pipeline: ' + str(completeness_end.mean(numeric_only=True) * 100) + '%,\\n' +\n",
    "    \"Average Shannon's Entropy Before Pipeline: \" + str(shannon_start) + ',\\n' +\n",
    "    \"Average Shannon's Entropy After Pipeline: \" + str(shannon_end) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm Before Pipeline: ' + str(accuracy_start) + ',\\n' +\n",
    "    'Accuracy on a ML Algorithm After Pipeline: ' + str(accuracy_end) + ',\\n' +\n",
    "    '# Cells Modified: ' + str(differences)\n",
    ")\n",
    "\n",
    "df_modified.to_csv(r'C:\\Users\\rocci\\OneDrive\\Desktop\\Università\\TesiMagistrale\\dataPreparationTool\\data\\output\\output6.csv', index = False)\n",
    "print(response)\n",
    "print(df_start.shape)\n",
    "print(df_modified.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
